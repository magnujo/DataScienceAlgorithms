{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "name": "Lab4 Decision Trees.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/magnujo/DataScienceAlgorithms/blob/main/Lab4_Decision_Trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHQSqjgpq_QJ"
      },
      "source": [
        "# Decision Trees\n",
        "Tree-based models work by partitioning the input space into rectangular regions, and then assigning simple (typically constant) model to each region.\n",
        "\n",
        "Tree-based models: Pro/Con\n",
        "* `+` simple\n",
        "* `+` powerful\n",
        "* `+` human understandable\n",
        "* `-` computationally expensive\n",
        "* `-` The optimal tree cannot be found efficiently. Therefore trees are built using a heuristic.\n",
        "\n",
        "In this notebook we will see how to make a simple decision tree.\n",
        "There are a couple of different kinds, but we will focus on one called CART (Classification and Regression Trees).\n",
        "CART is a nice to learn with, as it is easy to understand and implement.\n",
        "\n",
        "In this notebook we focus on **classification** on the Iris dataset, a classical data science dataset.\n",
        "The goal is to predict the type of iris plant ('setosa' 'versicolor' 'virginica') from sepal and petal dimensions.\n",
        "With only relatively minor changes the decision tree we make here could also be used for regression as well.\n",
        "\n",
        "![](https://www.wpclipart.com/plants/diagrams/plant_parts/petal_sepal_label.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E29J_htFq_QK"
      },
      "source": [
        "## CART\n",
        "A CART is a **binary tree**.\n",
        "* Inner nodes (non-leaf nodes) have a splitting rule, which can be described as `if-then` rules.\n",
        "If some condition is met, go to the left child, otherwise go to the right child.\n",
        "     * Each inner node queries one of the features, and checks whether it fulfils some condition, typically a threshold or equality.\n",
        "     * If the condition is met, go to the left child, otherwise go to the right child.\n",
        "* Continue like this until a leaf node is reached. Once a leaf node is reached assign $x$ to the corresponding label or value.\n",
        "\n",
        "\n",
        "The splitting rule should, at each node split the data, $S$, into $L_{d,\\theta}$ (left) and $R_{d,\\theta}$ (right) such that the information gain is maximized:\n",
        "$$\n",
        "G_{d,\\theta}(S) = Q(S) - \\frac{|L_{d,\\theta}|}{|S|}Q(L_{d,\\theta}) - \\frac{|R_{d,\\theta}|}{|S|}Q(R_{d,\\theta})\n",
        "$$\n",
        "Where $Q$ is some impurity measure.\n",
        "Until $|S|$ is smaller than some $s_{threshold}$ or all elements belong to the same class.\n",
        "Once the tree is grown it is common to prune to reduce its complexity - but we won't do that in this notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbWedyqmq_QL"
      },
      "source": [
        "## Loading the Data\n",
        "For this exercise we will combine the features and targets in one array.\n",
        "This makes keeping track of the data a bit easier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7GvZw6_q_QM"
      },
      "source": [
        "# ! git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V9yioAaq_QM",
        "outputId": "40071a9c-e8be-4203-dff4-d0255b9beec4"
      },
      "source": [
        "## Load the data\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "print(iris.DESCR)  # <-- Uncomment for more details on the data set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfYfSuvMq_QM",
        "outputId": "d0e706c9-1b77-4d92-cd7b-3022856512e0"
      },
      "source": [
        "data = np.concatenate([iris.data, iris.target[:,None]], axis=-1) # concatenate features and targets side by side\n",
        "\n",
        "# Split into train and test\n",
        "step_len = 10\n",
        "data_test = data[::step_len,:]\n",
        "np.random.shuffle(data_test)\n",
        "data_train = np.delete(data, [step_len*i for i in range(data_test.shape[0])], axis=0)#.reshape([-1, data.shape[1]])\n",
        "\n",
        "print('Feature Names:', iris.feature_names)\n",
        "print('Target Names: ', iris.target_names)\n",
        "print('data\\t\\t', data.shape)\n",
        "print('data_test\\t', data_test.shape)\n",
        "print('data_train\\t', data_train.shape)\n",
        "print()\n",
        "\n",
        "print('Example data')\n",
        "print(data_train[::15,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature Names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "Target Names:  ['setosa' 'versicolor' 'virginica']\n",
            "data\t\t (150, 5)\n",
            "data_test\t (15, 5)\n",
            "data_train\t (135, 5)\n",
            "\n",
            "Example data\n",
            "[[4.9 3.  1.4 0.2 0. ]\n",
            " [5.1 3.5 1.4 0.3 0. ]\n",
            " [4.9 3.1 1.5 0.2 0. ]\n",
            " [6.4 3.2 4.5 1.5 1. ]\n",
            " [5.8 2.7 4.1 1.  1. ]\n",
            " [5.4 3.  4.5 1.5 1. ]\n",
            " [5.8 2.7 5.1 1.9 2. ]\n",
            " [7.7 3.8 6.7 2.2 2. ]\n",
            " [6.1 2.6 5.6 1.4 2. ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwLUEyE64fWE",
        "outputId": "3f4236e7-2ab8-4c3f-adb8-b63fa06d181a"
      },
      "source": [
        "data_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.4, 3.7, 1.5, 0.2, 0. ],\n",
              "       [6.9, 3.2, 5.7, 2.3, 2. ],\n",
              "       [4.8, 3.1, 1.6, 0.2, 0. ],\n",
              "       [6.5, 3.2, 5.1, 2. , 2. ],\n",
              "       [7. , 3.2, 4.7, 1.4, 1. ],\n",
              "       [5.9, 3.2, 4.8, 1.8, 1. ],\n",
              "       [7.4, 2.8, 6.1, 1.9, 2. ],\n",
              "       [5.5, 2.4, 3.8, 1.1, 1. ],\n",
              "       [6.7, 3.1, 5.6, 2.4, 2. ],\n",
              "       [5.1, 3.5, 1.4, 0.2, 0. ],\n",
              "       [6.3, 3.3, 6. , 2.5, 2. ],\n",
              "       [5. , 3.5, 1.3, 0.3, 0. ],\n",
              "       [5.4, 3.4, 1.7, 0.2, 0. ],\n",
              "       [5.5, 2.6, 4.4, 1.2, 1. ],\n",
              "       [5. , 2. , 3.5, 1. , 1. ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqRSvsOuq_QN"
      },
      "source": [
        "## Useful helper functions.\n",
        "# Reading and understanding these is a good idea!\n",
        "\n",
        "def class_counts(data):\n",
        "    \"\"\"Counts the number of each class label in the input dataset.\"\"\"\n",
        "    counts = {}  # a dictionary of label -> count.\n",
        "    for row in data:\n",
        "        # in our dataset format, the label is always the last column\n",
        "        label = row[-1]\n",
        "        if label not in counts:\n",
        "            counts[label] = 0\n",
        "        counts[label] += 1\n",
        "    return counts\n",
        "\n",
        "def is_numeric(value):\n",
        "    \"\"\"Test if a value is numeric.\"\"\"\n",
        "    return isinstance(value, int) or isinstance(value, float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEdW6pKk5EYu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWj0G2f1q_QN",
        "outputId": "bf187c42-21da-4520-c24d-09c4df1b3cff"
      },
      "source": [
        "print('The class distribution is as follows:')\n",
        "print('Total:\\t', class_counts(data))\n",
        "print('Train:\\t', class_counts(data_train))\n",
        "print('Test:\\t', class_counts(data_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The class distribution is as follows:\n",
            "Total:\t {0.0: 50, 2.0: 50, 1.0: 50}\n",
            "Train:\t {0.0: 45, 1.0: 45, 2.0: 45}\n",
            "Test:\t {0.0: 5, 2.0: 5, 1.0: 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP4-46IJq_QN"
      },
      "source": [
        "# Task 1: Impurity Measure\n",
        "\n",
        "The first thing we need to do is to define an impurity measure.\n",
        "There are a couple of different to choose between\n",
        " * https://en.wikipedia.org/wiki/Decision_tree_learning#Metrics\n",
        "\n",
        "For this exercise we will use the Gini impurity (see Wikipedia).\n",
        "The Gini impurity is the probability of picking two different objects when drawing two random samples from the population.\n",
        "\n",
        "$$\n",
        "I_G(p) = 1 - \\sum_{i=1} p_i^2\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QHn3cQkQAUH",
        "outputId": "a0df6182-53cb-4a57-ace3-066c6c75f559"
      },
      "source": [
        "c = class_counts(data)\n",
        "for i in range(len(c)):\n",
        "  print(c[i])\n",
        "c"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n",
            "50\n",
            "50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.0: 50, 1.0: 50, 2.0: 50}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtDkiKB2q_QO",
        "outputId": "069b2aa5-059b-46de-af5c-ae2780c5e89f"
      },
      "source": [
        "import math\n",
        "def compute_impurity(data):\n",
        "    \"\"\" Calculate the impurity using the Gini Impurity Metric.\n",
        "        \n",
        "        Write the function generally, such that it works with different numbers of classes.\n",
        "    \"\"\"\n",
        "    # determine number of classes in data (last column)\n",
        "    label_counts = class_counts(data)\n",
        "    n = len(data)\n",
        "    impurity = 1\n",
        "\n",
        "    for i in range(len(label_counts)):\n",
        "      impurity = impurity - pow(label_counts[i]/n,2)\n",
        "\n",
        "    ## YOUR CODE HERE: Complete the implementation of the Gini Impurity calculation\n",
        "    \n",
        "    \n",
        "    return impurity\n",
        "\n",
        "print('Compare these results to the next text cell:')\n",
        "print('compute_impurity(data_class)\\t\\t', compute_impurity(data_train))\n",
        "print('compute_impurity(data_class[:90])\\t', compute_impurity(data_train[:90]))\n",
        "print('compute_impurity(data_class[:45])\\t', compute_impurity(data_train[:45]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compare these results to the next text cell:\n",
            "compute_impurity(data_class)\t\t 0.6666666666666665\n",
            "compute_impurity(data_class[:90])\t 0.5\n",
            "compute_impurity(data_class[:45])\t 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqjauZn3q_QO"
      },
      "source": [
        "**Expected Result (Solution):**\n",
        "\n",
        "compute_impurity(data_class)\t\t 0.6666666666666665\n",
        "\n",
        "compute_impurity(data_class[:90])\t 0.5\n",
        "\n",
        "compute_impurity(data_class[:45])\t 0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4GUsHPOq_QO"
      },
      "source": [
        "# Task 2: Branching\n",
        "> Estimated time: 30 minutes.\n",
        "\n",
        "The next thing we need to be able to do is use the impurity measure to split the data.\n",
        "A split is based on a `if-then` rule, here called a `Question`.\n",
        "A question is associated with a coordinate $d\\in \\{1, ..., D\\}$ (what feature are we asking about), and a threshold, $\\theta$.\n",
        "* E.g: if $x_d < \\theta$ go to left child, otherwise go to right child.\n",
        "\n",
        "Note that each feature is considered independently - therefore decision trees aren't affected by normalization.\n",
        "\n",
        "Your task is to:\n",
        "1. Finish the `match` method in the `Question` class. \n",
        " * Be sure that it can handle both categorican and numerical data (even though we only use numerical data here).\n",
        "1. Complete the `partition` function in the next cell.\n",
        " * Use `compute_impurity` and `Question` to do so."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0lMga3Fq_QP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "690fd0cd-9776-422a-e9e7-62a63a3528c6"
      },
      "source": [
        "class Question:\n",
        "    \"\"\" A Question is used to partition a dataset.\n",
        "        This class just records a 'column number' (aka coordinate) and a\n",
        "        'column value' (aka threshold). The 'match' method is used to compare\n",
        "        the feature value in an example to the feature value stored in the\n",
        "        question. \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, column, value):\n",
        "        self.column = column\n",
        "        self.value = value\n",
        "        self.value_is_numerical = is_numeric(self.value)\n",
        "\n",
        "    def __repr__(self):\n",
        "        # Helper method to print in a readable format.\n",
        "        condition = \"==\"\n",
        "        if self.value_is_numerical:\n",
        "            condition = \">=\"\n",
        "        return \"Is %s %s %s?\" % (\n",
        "            iris.feature_names[self.column], condition, str(self.value))\n",
        "        \n",
        "    def match(self, example):\n",
        "        \"\"\" Takes a single example (a single row) and compares \n",
        "            it with the feature value in this question.\n",
        "            \n",
        "            Returns: Bool\n",
        "        \"\"\"\n",
        "        if example[self.column] >= self.value:\n",
        "          return True\n",
        "        else:\n",
        "          return False\n",
        "        \n",
        "        \n",
        "\n",
        "        \n",
        "# Example of a Question:\n",
        "print(Question(1, 3.2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is sepal width (cm) >= 3.2?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZZw4Rlaq_QQ"
      },
      "source": [
        "def partition(rows, question):\n",
        "    \"\"\" Partitions a dataset:\n",
        "        For each row in the dataset, check if it matches the question. \n",
        "        If so, add it to 'true rows', otherwise, add it to 'false rows'.\n",
        "        \n",
        "        Returns: true_rows, false_rows\n",
        "    \"\"\"\n",
        "    \n",
        "    true_rows, false_rows = [], []\n",
        "\n",
        "    for row in rows:\n",
        "      if question.match(row):\n",
        "        true_rows.append(row)\n",
        "      else:\n",
        "        false_rows.append(row)\n",
        "    \n",
        "    \n",
        "\n",
        "    return true_rows, false_rows\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHGIMlcnq_QQ"
      },
      "source": [
        "# Task 3: Best Split\n",
        "\n",
        "> Estimated time: 30 minutes.\n",
        "\n",
        "Now that we know how to split we need to determine where to split!\n",
        "The best split is the one that maximizes the **information gain**, as determiend by the impurity measure.\n",
        "\n",
        "$$\n",
        "G_{d,\\theta}(S) = Q(S) - \\frac{|L_{d,\\theta}|}{|S|}Q(L_{d,\\theta}) - \\frac{|R_{d,\\theta}|}{|S|}Q(R_{d,\\theta})\n",
        "$$\n",
        "\n",
        "\n",
        "Your task is to:\n",
        "1. Complete the `find_best_split` function. \n",
        "\n",
        " * You will need to combine several things: `compute_impurity`, `Question`, `partition`, and `info_gain`.\n",
        " * Hint: Structure your code as a double for-loop such that you examine whether each value for each feature is a good threshold.\n",
        "    * Loop through all the features \n",
        "    * For each unique value of the current feature, create a `Question` and check if it is good.\n",
        "    * Return the best information gain, and the question that lead to it. (or `0, None` if no good questions exist)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcmrkAL8q_QQ"
      },
      "source": [
        "def info_gain(left, right, current_uncertainty):\n",
        "    \"\"\" Information Gain.\n",
        "        The uncertainty of the starting node, minus the weighted impurity of two child nodes.\n",
        "    \"\"\"\n",
        "    p = float(len(left)) / (len(left) + len(right))\n",
        "    return current_uncertainty - p * compute_impurity(left) - (1 - p) * compute_impurity(right)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwoSeY_oq_QR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "outputId": "427a5a00-0fc1-47b5-9986-6785af901615"
      },
      "source": [
        "def find_best_split(rows):\n",
        "    \"\"\" Find the best split by finding the information gain for each possible split.\n",
        "    \n",
        "        Returns: best_gain, best_question\n",
        "    \"\"\"\n",
        "    best_gain = 0  # keep track of the best information gain\n",
        "    best_question = None  # keep track of the feature / value that produced it\n",
        "    current_uncertainty = compute_impurity(rows)\n",
        "    n_features = len(rows[0]) - 1  # number of columns\n",
        "    for i in range(n_features):\n",
        "      uniq_vals = set()\n",
        "      for row in rows:\n",
        "        uniq_vals.add(row[i])\n",
        "      for val in uniq_vals:\n",
        "        q = Question(i, val)\n",
        "        l, r = partition(rows, q)\n",
        "        ig = info_gain(l, r, current_uncertainty)\n",
        "        if ig > best_gain:\n",
        "          best_gain = ig\n",
        "          best_question = q\n",
        "      \n",
        "\n",
        "  \n",
        "    ## YOUR CODE HERE\n",
        "    \n",
        "    \n",
        "    return best_gain, best_question\n",
        "\n",
        "print(find_best_split(data))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-d3ae3d696a10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_gain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_question\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_best_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-100-d3ae3d696a10>\u001b[0m in \u001b[0;36mfind_best_split\u001b[0;34m(rows)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQuestion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo_gain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_uncertainty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mig\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_gain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m           \u001b[0mbest_gain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-98-7664435708e2>\u001b[0m in \u001b[0;36minfo_gain\u001b[0;34m(left, right, current_uncertainty)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcurrent_uncertainty\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcompute_impurity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcompute_impurity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-95-bdc3c01d8745>\u001b[0m in \u001b[0;36mcompute_impurity\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mimpurity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimpurity\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m## YOUR CODE HERE: Complete the implementation of the Gini Impurity calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpEct58kq_QR"
      },
      "source": [
        "# Task 4: Growing Trees\n",
        "\n",
        "Now we have all the ingredients to start growing trees.\n",
        "Have a look, and see if that works.\n",
        "\n",
        "\n",
        "`build_tree` function is implemented using **recursion**.\n",
        "Each iteration checks whether we shuold create a `Leaf_Node` (the base case) or it partitions the input date, and recursively calls itself on both partitions.\n",
        "The result of the recursive function is saved as a `Decision_Node`.\n",
        "\n",
        "\n",
        "`classify` is als implemented with recursion function.\n",
        "The function takes **one** observation, and return the predicted class, by at each `Decision_Node` asking the `Question`.\n",
        "Based on the answer follow the true-branch or the false-branch until you hit a `Leaf_Node`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY6JVeXJq_QR"
      },
      "source": [
        "class Leaf_Node:\n",
        "    \"\"\" A Leaf_Node classifies data.\n",
        "        This holds a dictionary of class (e.g., \"Apple\") -> number of times\n",
        "        it appears in the rows from the training data that reach this leaf.\n",
        "    \"\"\"\n",
        "    def __init__(self, rows):\n",
        "        self.predictions = class_counts(rows)\n",
        "\n",
        "class Decision_Node:\n",
        "    \"\"\" A Decision Node asks a question.\n",
        "        This holds a reference to the question, and to the two child nodes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 question,\n",
        "                 true_branch,\n",
        "                 false_branch):\n",
        "        \n",
        "        self.question = question\n",
        "        self.true_branch = true_branch\n",
        "        self.false_branch = false_branch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xarvedkq_QS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "278c4620-91f8-4210-fa76-a2270a2f664c"
      },
      "source": [
        "def build_tree(rows):\n",
        "    \"\"\" Builds the tree.\n",
        "    \"\"\"\n",
        "\n",
        "    # Find the best split by finding the information gain for each possible split\n",
        "    gain, question = find_best_split(rows)\n",
        "\n",
        "    # Base case: no further info gain\n",
        "    # Since we can ask no further questions,\n",
        "    # we'll return a leaf.\n",
        "    if gain == 0:\n",
        "        return Leaf_Node(rows)\n",
        "\n",
        "    # If we reach here, we have found a useful feature / value\n",
        "    # to partition on.\n",
        "    true_rows, false_rows = partition(rows, question)\n",
        "\n",
        "    # Recursively build the true branch.\n",
        "    true_branch = build_tree(true_rows)\n",
        "\n",
        "    # Recursively build the false branch.\n",
        "    false_branch = build_tree(false_rows)\n",
        "\n",
        "    # Return a Question node.\n",
        "    # This records the best feature / value to ask at this point,\n",
        "    # as well as the branches to follow\n",
        "    # dependingo on the answer.\n",
        "    return Decision_Node(question, true_branch, false_branch)\n",
        "\n",
        "my_tree = build_tree(data_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-4f7a0f85369e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mDecision_Node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_branch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_branch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mmy_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-101-4f7a0f85369e>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(rows)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Find the best split by finding the information gain for each possible split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mgain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_best_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Base case: no further info gain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-100-d3ae3d696a10>\u001b[0m in \u001b[0;36mfind_best_split\u001b[0;34m(rows)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQuestion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo_gain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_uncertainty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mig\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_gain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m           \u001b[0mbest_gain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-98-7664435708e2>\u001b[0m in \u001b[0;36minfo_gain\u001b[0;34m(left, right, current_uncertainty)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcurrent_uncertainty\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcompute_impurity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcompute_impurity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-95-bdc3c01d8745>\u001b[0m in \u001b[0;36mcompute_impurity\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mimpurity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimpurity\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m## YOUR CODE HERE: Complete the implementation of the Gini Impurity calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzwF457kq_QS"
      },
      "source": [
        "def classify(row, node):\n",
        "    \"\"\" Recursively search\n",
        "    \"\"\"\n",
        "    \n",
        "    # Base Case:\n",
        "    if isinstance(node, Leaf_Node):\n",
        "        return node.predictions\n",
        "    \n",
        "    # Recursion: decide whether to follow the true-branch or the false-branch.\n",
        "    # Compare the feature / value stored in the node,\n",
        "    # to the example we're considering (question.match)\n",
        "    ## YOUR CODE HERE\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmKshOARq_QS"
      },
      "source": [
        "# Visualizing Results\n",
        "\n",
        "Now comes the fun part!\n",
        "Run the cells below, and interpret the results.\n",
        "\n",
        "Note that the Iris dataset is a quite simple dataset, and you shouldn't expect to get nearly this good results in general."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlLh_KFUq_QS"
      },
      "source": [
        "def print_tree(node, spacing=\"\"):\n",
        "    \"\"\" World's most elegant tree printing function.\"\"\"\n",
        "\n",
        "    # Base case: we've reached a leaf\n",
        "    if isinstance(node, Leaf_Node):\n",
        "        print (spacing + \"Predict\", node.predictions)\n",
        "        return\n",
        "\n",
        "    # Print the question at this node\n",
        "    print (spacing + str(node.question))\n",
        "\n",
        "    # Call this function recursively on the true branch\n",
        "    print (spacing + '--> True:')\n",
        "    print_tree(node.true_branch, spacing + \"  \")\n",
        "\n",
        "    # Call this function recursively on the false branch\n",
        "    print (spacing + '--> False:')\n",
        "    print_tree(node.false_branch, spacing + \"  \")\n",
        "\n",
        "print_tree(my_tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTdg8lI-q_QT"
      },
      "source": [
        "def print_leaf(counts):\n",
        "    \"\"\"A nicer way to print the predictions at a leaf.\"\"\"\n",
        "    total = sum(counts.values()) * 1.0\n",
        "    probs = {}\n",
        "    for lbl in counts.keys():\n",
        "        probs[lbl] = str(int(counts[lbl] / total * 100)) + \"%\"\n",
        "    return probs\n",
        "\n",
        "acc = 0\n",
        "for row in data_test:\n",
        "    pred = classify(row, my_tree)\n",
        "    print (\"Actual: %s. Predicted: %s\" % (row[-1], print_leaf(pred)))\n",
        "    \n",
        "    if row[-1] in pred:\n",
        "        acc += 1\n",
        "\n",
        "print()\n",
        "print('Accuracy:', acc/data_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fqv0yz_9q_QT"
      },
      "source": [
        "## Credits\n",
        "This notebook is made heavily inspired and borrowing from: [Google Developers: Machine Learning Recipes #8](https://www.youtube.com/watch?v=LDRbO9a6XPU) ([source code](https://github.com/random-forests/tutorials/)).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ouy5PfgQq_QT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}